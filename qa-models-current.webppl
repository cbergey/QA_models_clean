//  -----------
// | utilities |
//  ----------

// poor person's barplot emulation for terminal
var terminalViz = function(dist, precisionLevel) {

  var unfiltered_support = dist.support();
  var unfiltered_probs   = map(function(x) {
    return 1*dist.score(x).toPrecision(precisionLevel)}, dist.support())

  var unsorted_probs   = filter(function(x) {return Math.exp(x) > 0},
                                unfiltered_probs)
  var unsorted_support = filter(function(x) {return Math.exp(dist.score(x)) > 0},
                                unfiltered_support )

  var sorted_probs     = sort(unsorted_probs);
  var sortFunction = function(x) {
    return -1*dist.score(x).toPrecision(precisionLevel)
  }
  var sorted_support   = sortOn(unsorted_support, sortFunction)
  var max_length_element = _.max(map(function(e) {e.length}, sorted_support));
  var scores = map(function(x) {
    return 1*Math.exp(dist.score(x).toPrecision(precisionLevel)).toPrecision(precisionLevel)
  }, sorted_support)
  var maxScore =  _.max(map(function(e) {e}, scores));
  map(
    function(x) {
      var score = 1*Math.exp(dist.score(x).toPrecision(precisionLevel)).toPrecision(precisionLevel)
      console.log(" ",
                  _.padEnd(x, max_length_element, " "),
                  ": ",
                  _.padEnd(_.repeat('*', score*20), 21),
                  score
                 )}
    , sorted_support)
  return "  ===viz==="
}

var butLast = function(xs){
  return xs.slice(0, xs.length-1);
};

var KL = function(dist1, dist2){
  var values = dist1.support();
  return sum(map(function(value){
    var scoreP = dist1.score(value);
    var scoreQ = dist2.score(value);
    var probP = Math.exp(scoreP);
    var probQ = Math.exp(scoreQ);
    return (probP == 0.0 ? 0.0 :
            probQ == 0.0 ? 1000000:
            probP * (scoreP - scoreQ));
  }, values));
};

var SumSquares = function(dist1, dist2){
  var values = dist1.support();
  return sum(map(function(value){
    var scoreP = dist1.score(value);
    var scoreQ = dist2.score(value);
    var probP = Math.exp(scoreP);
    var probQ = Math.exp(scoreQ);
    return ((scoreP - scoreQ)^2);
  }, values));
};

var powerset = function(set) {
  if (set.length == 0) {
    return [[]];
  } else {
    var rest = powerset(set.slice(1));
    return map(function(element) {
      return [set[0]].concat(element);
    }, rest).concat(rest);
  }
};

//  -------------------
// | global parameters |
//  -------------------

var params = {
  R0Alpha : 0.0001,
  questionerAlpha : 3,
  R1Alpha : 5,
  relevanceBetaR0: 0,     // beta=1 for only action-utility
  relevanceBetaR1: 0.8,   //
  costWeight: 0.15
};

//  --------------------------
// | preparing context models |
//  --------------------------

var bakedGoods = ['raspPie', 'raspCake', 'lemonPie', 'lemonCake'];
var bakedGoodsMinimal = ['RP', 'LC', 'SC', 'AS'];

// create string representation of all subsets of baked goods
var setWithEmptyListElement = map(
  function(v){return v.join('+');},
  // add possibility to encode background knowledge of number k of available goods
  filter(function(x) {return x.length <= 4}, powerset(bakedGoods))
);
var replaceEmptyListWithStringNothing = function(set) {
  _.concat(filter(
    function(x) {
      if (x != "") {
        return x
      }
    },
    set
  ), "nothing");
}
var setWithStringNothing = replaceEmptyListWithStringNothing(setWithEmptyListElement);
var setsOfBakedGoods = setWithStringNothing;

// build response set for pragmatic respondent (R1)
var sampleR1PolarResponses = Infer(
  {method: 'enumerate'},
  function() {
    var yesNoPart = uniformDraw(["yes", "no"]);
    var itemPart = uniformDraw(_.concat(filter(
      function(x) {
        if (x != "") {
          return x
        }
      },
      setsOfBakedGoods
    ), "---", "nothing"));
    return [yesNoPart, itemPart].join(".")
  }
)
var R1PolarResponses = filter(
  function(r) {
    // some responses can never be true
    r != "yes.nothing" && r != "no.raspPie+raspCake+lemonPie+lemonCake"
  },
  sampleR1PolarResponses.support());
var R1WHResponses = setsOfBakedGoods;

// var pieCakeContextMinimal = {
//   name : "minimal",
//   // worlds include all possible sub-sets of 0 < k < N pies and cakes
//   worlds : bakedGoodsMinimal,

//   // actions include ordering 1 pie/cake
//   actions: bakedGoodsMinimal,

//   // questions include yes/no question for each baked good
//   questions: [
//     // single item polar questions
//     {type: 'polar-disjunct', queried: ['RP'], text: 'RP?'},
//     {type: 'polar-disjunct', queried: ['LC'], text: 'LC?'},
//     {type: 'polar-disjunct', queried: ['SC'], text: 'SC?'},
//     {type: 'polar-disjunct', queried: ['AS'], text: 'AS?'},
//     // all two-place disjunctions
//     // {type: 'polar-disjunct', queried: ['RP', 'LC'], text: 'RPorLC?'},
//     // {type: 'polar-disjunct', queried: ['RP', 'SC'], text: 'RPorSC?'},
//     // {type: 'polar-disjunct', queried: ['RP', 'AS'], text: 'RPorAS?'},
//     // {type: 'polar-disjunct', queried: ['LC', 'SC'], text: 'LCorSC?'},
//     // {type: 'polar-disjunct', queried: ['LC', 'AS'], text: 'LCorAS?'},
//     // {type: 'polar-disjunct', queried: ['SC', 'AS'], text: 'SCorAS?'},
//     // wh-question
//     {type: 'wh', queried: bakedGoodsMinimal, text: 'which?'},
//   ],

//   // assume questioner is uncertain but answerer has Delta on true world (e.g. shopkeep)
//   questionerBeliefs: Categorical({vs: bakedGoodsMinimal}),
//   R0PriorOverWorlds: Delta({v: 'RP'}),

//   // raspberry pie is #1 preference (U=5), lemon cake is #2 preference (U=4).
//   // otherwise U=1 if whatever you order is in stock and 0 if it's not in stock
//   decisionProblem: function(w, a) {
//     return _.includes(w, a) ? 1 : 0.0000001;
//   },
//   meaning: function(world, question, response) {
//     if(response == '') {
//       // assume silence has null meaning
//       return true;
//     }
//     if(question.type == 'polar-disjunct') {
//       return (response == 'yes' ? _.includes(question.queried, world) :
//               response == 'no' ?  (! _.includes(question.queried, world)) : 0);
//     } else if(question.type == 'wh') {
//       return world == response;
//     } else {
//       return console.error('question type not yet supported: ' + question.type);
//     }
//   },
//   // R0 chooses among responses licensed by the question
//   getLicensedResponsesR0: function(question) {
//     if(question.type == 'polar-disjunct') {
//       return ['yes', 'no'];
//     } else if(question.type == 'wh') {
//       return bakedGoodsMinimal;
//     } else {
//       return console.error('question type not yet supported: ' + question.type);
//     }
//   }
// };

// // amended context with unbiased questioner beliefs and no preferences over any baked good
// var pieCakeContextMinimalWithPreferences = extend(
//   pieCakeContextMinimal,
//   {
//     name : "minimal-with-preferences",
//     // respondent knows true answer
//     R0PriorOverWorlds: Delta({v: 'lemonCake'}),
//     // no preferences over baked goods
//     questions: [
//       // single item polar questions
//       {type: 'polar-disjunct', queried: ['RP'], text: 'RP?'},
//       {type: 'polar-disjunct', queried: ['LC'], text: 'LC?'},
//       {type: 'polar-disjunct', queried: ['SC'], text: 'SC?'},
//       {type: 'polar-disjunct', queried: ['AS'], text: 'AS?'},
//       // all two-place disjunctions
//       // {type: 'polar-disjunct', queried: ['RP', 'LC'], text: 'RPorLC?'},
//       // {type: 'polar-disjunct', queried: ['RP', 'SC'], text: 'RPorSC?'},
//       // {type: 'polar-disjunct', queried: ['RP', 'AS'], text: 'RPorAS?'},
//       // {type: 'polar-disjunct', queried: ['LC', 'SC'], text: 'LCorSC?'},
//       // {type: 'polar-disjunct', queried: ['LC', 'AS'], text: 'LCorAS?'},
//       // {type: 'polar-disjunct', queried: ['SC', 'AS'], text: 'SCorAS?'},
//       // wh-question
//       {type: 'wh', queried: bakedGoodsMinimal, text: 'which?'},
//     ],
//     decisionProblem: function(w, a) {
//       return _.includes(w, a) ? (a == 'RP' ? 5 : a == 'LC' ? 3 : 1) : 0.0000001;
//     }
//   }
// )

// richer context w/ powerset of baked goods

var pieCakeContext = {
  name : "pieCake-prefs",
  // worlds include all possible sub-sets of 0 < k < N pies and cakes
  worlds : setsOfBakedGoods,

  // actions include ordering 1 pie/cake
  actions: _.concat(bakedGoods, "nothing"),

  // questions include yes/no question for each baked good
  questions: [
    {type: 'single-item', queried: ['lemonPie'], text: 'Lemon pie?'},
    {type: 'single-item', queried: ['lemonCake'], text: 'Lemon cake?'},
    {type: 'single-item', queried: ['raspPie'], text: 'Raspberry pie?'},
    {type: 'single-item', queried: ['raspCake'], text: 'Raspberry cake?'},
    {type: 'polar-disjunct', queried: ['lemonPie', 'raspPie', 'lemonPie+raspPie'], text: 'Pie?'},
    {type: 'polar-disjunct', queried: ['lemonCake', 'raspCake', 'lemonCake+raspCake'], text: 'Cake?'},
//     {type: 'polar-disjunct', queried: ['lemonCake', 'raspCake', 'lemonPie', 'raspPie'], text: 'Anything?'},
    // MF additional disjunctions
    {type: 'polar-disjunct', queried: ['lemonPie', 'lemonCake', 'lemonPie+lemonCake'], text: 'Anything w/ lemon?'},
    {type: 'polar-disjunct', queried: ['raspPie', 'raspCake', 'raspPie+raspCake'], text: 'Anything w/ raspberry?'},
    {type: 'polar-disjunct', queried: ['lemonPie', 'raspCake', 'lemonPie+raspCake'], text: 'LP or RC?'},
    {type: 'polar-disjunct', queried: ['lemonCake', 'raspPie', 'lemonCake+raspPie'], text: 'RP or LC?'},
    {type: 'wh', queried: ['lemonCake', 'raspCake'], text: 'Which cakes?'},
    {type: 'wh', queried: ['lemonPie', 'raspPie'], text: 'Which pies?'},
    {type: 'wh', queried: ['lemonPie', 'lemonCake', 'raspPie', 'raspCake'], text: 'Which goods?'},
  ],

  // assume questioner is uncertain but answerer has Delta on true world (e.g. shopkeep)
  questionerBeliefs: Categorical({vs: setsOfBakedGoods}),
  R0PriorOverWorlds: Delta({v: 'lemonCake'}),
  R1PriorOverWorlds: Delta({v: 'lemonCake'}),

  // raspberry pie is #1 preference (U=5), lemon cake is #2 preference (U=4).
  // otherwise U=1 if whatever you order is in stock and 0 if it's not in stock
  decisionProblem: function(w, a) {
    return _.includes(w, a) ?
      (a == 'raspPie' ? 5 :
       a == 'lemonCake' ? 3 : 1) :
    0.0000001;
  },

  // R0 chooses among responses licensed by the question
  getLicensedResponsesR0: function(question) {
    if(question.type == 'single-item') {
      // by definition polar questions require 'yes'/'no' answer
      return ['yes', 'no'];
    } else if(question.type == 'polar-disjunct') {
      // by definition polar questions require 'yes'/'no' answer
      var answers = ['yes', 'no'].concat(question.queried);
      return answers;
    } else if(question.type == 'wh') {
      // 'wh' questions allow you to say any set of queried items,
      // or to say "nothing" when none of the querried items exist
      return replaceEmptyListWithStringNothing(
        map(
          function(v){return v.join('+');},
          powerset(question.queried)
      ));
    } else {
      return console.error('question type not yet supported: ' + question.type);
    }
  },

  // R1 chooses among responses licensed by the question
  getLicensedResponsesR1: function(question) {
    return (question.type == 'wh' ?
            R1WHResponses : R1PolarResponses)
  },
  // semantic meaning function
  meaning: function(world, question, response) {

    // meaning of literals / atoms
    var meaning_atomic = function(world, question, response) {
      // console.log(" *** now evaluating response: part ", response)
      if(response == '' || response == "---") {
        // assume silence has null meaning
        return true;
      }
      if(response == "nothing") {
        if(world == "nothing") {
          return true;
        }
      }
      if(world == "nothing" && question.type == 'wh') {
        return response == "nothing";
      }
      if(question.type == 'single-item') {
        return (
          response == 'yes' ? _.intersection(world.split('+'), question.queried).length > 0 :
            response == 'no' ?  _.intersection(world.split('+'), question.queried).length == 0 :
            all(function(item) {
              return _.includes(world.split('+'), item);
            }, response.split('+')));
        // return (
        //   response == 'yes' ? _.intersection(world.split('+'), question.queried).length > 0 :
        //     response == 'no' ?  _.intersection(world.split('+'), question.queried).length == 0 :
        //     console.error('Not a valid response to question:', question, response));
      } else
        if(question.type == 'polar-disjunct') {
          return (
            response == 'yes' ? _.intersection(world.split('+'), question.queried).length > 0 :
              response == 'no' ?  _.intersection(world.split('+'), question.queried).length == 0 :
              all(function(item) {
                return _.includes(world.split('+'), item);
              }, response.split('+')));
        } else if(question.type == 'wh') {
          // assume response is true when the shop contains every mentioned item
          return all(function(item) {
            return _.includes(world.split('+'), item);
          }, response.split('+'));
        } else {
          return console.error('question type not yet supported: ' + question.type);
        }
    }

    // meaning of conjunctions

    return all(
      function (r) {
        meaning_atomic(world, question, r)
      },
      _.split(response, '.')
    )

  }
};

// amended context with feature-based (additive) preferences
var pieCakeContextAdditivePreferences = extend(
  pieCakeContext,
  {
    name : "pieCake-prefs-additive",
    // feature-additive preferences: pie = 2, cake = 1, rasp = 6, lemon = 4;
    decisionProblem: function(w, a) {
      return _.includes(w, a) ? (a == 'raspPie'   ? 8/2 :
                                 a == 'raspCake'  ? 7/2 :
                                 a == 'lemonPie'  ? 6/2 :
                                 a == 'lemonCake' ? 5/2 :
                                 a == 'nothing'   ? 1/2 :
                                 console.error('unknown action')
                                ) : 0.0000001;
    }
  }
)

// amended context with feature-based (additive) preferences (reversed)
var pieCakeContextAdditivePreferencesReversed = extend(
  pieCakeContext,
  {
    name : "pieCake-prefs-additive-reversed",
    // feature-additive preferences: pie = 4, cake = 6, rasp = 1, lemon = 2;
    decisionProblem: function(w, a) {
      return _.includes(w, a) ? (a == 'raspPie'   ? 5/2 :
                                 a == 'raspCake'  ? 7/2 :
                                 a == 'lemonPie'  ? 6/2 :
                                 a == 'lemonCake' ? 8/2 :
                                 a == 'nothing'   ? 1/2 :
                                 console.error('unknown action')
                                ) : 0.0000001;
    }
  }
)

// amended context with topic preference (dough is irrelevant)
//   agent prefers raspberry over lemon and rather has nothing than lemon
var pieCakeContext_raspberry = extend(
  pieCakeContext,
  {
    name : "raspberry-pref",
    decisionProblem: function(w, a) {
      return _.includes(w, a) ? (a == 'raspPie'   ? 7/2 :
                                 a == 'raspCake'  ? 7/2 :
                                 a == 'lemonPie'  ? 1/2 :
                                 a == 'lemonCake' ? 1/2 :
                                 a == 'nothing'   ? 2/2 :
                                 console.error('unknown action')
                                ) : 0.0000001;
    }
  }
)
//   like the previous but reversed (lemon > nothing > raspberry)
var pieCakeContext_lemon = extend(
  pieCakeContext,
  {
    name : "lemon-pref",
    decisionProblem: function(w, a) {
      return _.includes(w, a) ? (a == 'raspPie'   ? 1/2 :
                                 a == 'raspCake'  ? 1/2 :
                                 a == 'lemonPie'  ? 7/2 :
                                 a == 'lemonCake' ? 7/2 :
                                 a == 'nothing'   ? 2/2 :
                                 console.error('unknown action')
                                ) : 0.0000001;
    }
  }
)


// amended context with unbiased questioner beliefs and no preferences over any baked good
var pieCakeContextUnbiasedNoPref = extend(
  pieCakeContext,
  {
    name : "pieCake-no-prefs",
    // respondent knows true answer
    R0PriorOverWorlds: Delta({v: 'lemonCake'}),
    // no preferences over baked goods
    decisionProblem: function(w, a) {
      return _.includes(w, a) ? 1 : 0.0000001;
    }
  }
)

// amended context with biased questioner beliefs and no preferences over any baked good
var pieCakeContextBiasedNoPref = extend(
  pieCakeContextUnbiasedNoPref,
  {
    name : "pieCake-no-prefs-over-confident",
    // assume questioner is virtually certain that they have either raspberry pie
    // or lemon cake (but not both)
    questionerBeliefs: Categorical({
      vs: setsOfBakedGoods,
      ps: map(
        function (x) {
          return x == 'raspPie' ? 1000 : x == 'lemonCake' ? 1000 : 1
        },
        setsOfBakedGoods
      )
    })
  }
)

// amended context with biased, heavily pessimistic beliefs & no preferences
var pieCakeContextBiasedPessimist = extend(
  pieCakeContextUnbiasedNoPref,
  {
    name : "pieCake-no-prefs-pessimist",
    // questioner believes that the shop has likely no or very few items
    questionerBeliefs: Categorical({
      vs: setsOfBakedGoods,
      ps: map(
        function (x) {
          return (x == 'nothing' ? 100 :
                  x.split('+').length == '1' ? 10 :
                  x.split('+').length == '2' ? 1 :
                  x.split('+').length == '3' ? 0.1 :
                  x.split('+').length == '4' ? 0.01 :
                  0.000000001)
        },
        setsOfBakedGoods
      )
    })
  }
)

// response cost is proportional to length in words
var cost = function(response) {
  return _.includes(response, "---") ? 0 : params.costWeight * (response.split('+').length);
};

//  -----------
// | Q&A model |
//  -----------

// weight possible actions proportional to EU
// yields the 'action policy' of the decision maker
var relevanceProjection = function(beliefs, context) {
  return Infer({method: 'enumerate'}, function() {
    var action = uniformDraw(context.actions);
    var world = sample(beliefs);
    var decisionProblem = context.decisionProblem;
    // console.log(world, action);
    // console.log(Math.log(decisionProblem(world, action)));
    factor(Math.log(decisionProblem(world, action)));
    return action;
  });
};

// returns TRUE if a response is contradictory in the light of the question
// example: "Do you have any pie?" "No, we have lemon pie."
var isContradiction = function(context, question, response) {
  var meaning = context.meaning;
  var isContra = all(
    function(world) {
      !meaning(world,question,response)
    },
    context.worlds
  )
  // if (isContra) {
  //   console.log("Contradiction hit: ", question.text, response)
  // }
  return isContra
}

// gives updated beliefs about world state after hearing response to question
// based on a literal interpretation of the response
var updateBeliefs = function(beliefs, question, response, context) {
  var meaning = context.meaning;
  return Infer({method: 'enumerate'}, function() {
    var world = sample(beliefs);
    condition(meaning(world, question, response));
    return world;
  });
};

// utility of a question is equal to the expected _value_ of the
// DP after receiving a response; _value_ depends on DM's action policy
var questionUtility = function(utterance, beliefs, context) {
  // questioner wants to *maximize* expected payoff under decision problem
  var decisionProblem = context.decisionProblem;
  var actionPolicy = relevanceProjection(beliefs, context);
  var actionUtility = expectation(actionPolicy, function(action) {
    // weight possible actions proportional to reward
    return expectation(beliefs, function(world) {
      return decisionProblem(world, action);
    });
  });
  return actionUtility - cost(utterance);
};

// responder wants to bring questioner's beliefs and/or action policy
// as close to their own as possible
var answerUtility = function(utterance, beliefs1, beliefs2, context, relevanceBeta) {
  // respondent wants to *minimize* KL b/w beliefs (bringing closer to own belief)
  var epistemicUtility = -KL(beliefs1, beliefs2);
  var actionUtility = -KL(relevanceProjection(beliefs1, context),
                          relevanceProjection(beliefs2, context));
  return ((1 - relevanceBeta) * epistemicUtility
          + relevanceBeta * actionUtility
          - cost(utterance));
};

// base-level respondent chooses any safe and true answer
// with equal probability
var R0 = cache(function(question, context) {
  var getLicensedResponsesR0 = context.getLicensedResponsesR0;
  return Infer({method: 'enumerate'}, function(){
    var response = uniformDraw(getLicensedResponsesR0(question));
//     console.log(response);
    var ownBeliefs = context.R0PriorOverWorlds;
    var otherBeliefs = updateBeliefs(context.questionerBeliefs, question, response, context);
//     console.log('updated beliefs', otherBeliefs);
    factor(params.R0Alpha * answerUtility(response, ownBeliefs, otherBeliefs, context, params.relevanceBetaR0));
    return response;
  });
});

// dummy R0 with response set of R1
var R0_extended = cache(function(question, context) {
  var getLicensedResponsesR1 = context.getLicensedResponsesR1;
  var responses = filter(function(r) {!isContradiction(context, question, r)},
                         getLicensedResponsesR1(question));
  return Infer({method: 'enumerate'}, function(){
    var response = uniformDraw(responses);
    // console.log(response);
    var ownBeliefs = context.R0PriorOverWorlds;
    var otherBeliefs = updateBeliefs(context.questionerBeliefs, question, response, context);
    // console.log('updated beliefs: ');
    // terminalViz(otherBeliefs, 4);
    factor(10 * (-KL(ownBeliefs, otherBeliefs) - cost(response)));
    return response;
  });
});

// gives updated beliefs about world state after hearing response to question
// based on a pragmatic interpretation of the response (as emitted by R0)
var updateBeliefsPragmatic = function(beliefs, question, response, context) {
  var meaning = context.meaning;
  return Infer({method: 'enumerate'}, function() {
    var world = sample(beliefs);
    var pragmaticResponse = R0(question, extend(context, {
      R0PriorOverWorlds: Delta({v: world})
    }));
    observe(pragmaticResponse,response)
    return world;
  });
};

// gives updated beliefs about world state after hearing response to question
// based on a pragmatic interpretation (as emitted by R0 w/ full answer set of R1)
var updateBeliefsPragmaticR1 = function(beliefs, question, response, context) {
  var meaning = context.meaning;
  return Infer({method: 'enumerate'}, function() {
    var world = sample(beliefs);
    var pragmaticResponse = R0_extended(question, extend(context, {
      R0PriorOverWorlds: Delta({v: world})
    }));
    observe(pragmaticResponse,response)
    return world;
  });
};

// Q1 selects a question with prob proportional to the expected
// value of the DP after hearing a response
var Q1 = cache(function(context) {
  return Infer({method: 'enumerate'}, function(){
    var question = uniformDraw(context.questions);
    // console.log('considering question', question.queried);
    var expectedUtility = expectation(context.questionerBeliefs, function(trueWorld) {
      // console.log('in possible world', trueWorld);
      var possibleResponses = R0(question, extend(context, {
        R0PriorOverWorlds: Delta({v: trueWorld})
      }))
      // console.log('respondent: ', possibleResponses)
      return expectation(possibleResponses, function(response) {
        // console.log('considering response ', response );
        var currBeliefs = context.questionerBeliefs;
        var updatedBeliefs = updateBeliefsPragmatic(currBeliefs, question, response, context);
        return questionUtility(response, updatedBeliefs, context);
      });
    });
//     console.log('expected utility: ',expectedUtility)
    factor(params.questionerAlpha * expectedUtility);
    return question.text;
  });
});

// console.log(myDF);
// var context =
//     myDF[0].context == 'pieCakeContextMinimal' ? pieCakeContextMinimal :
//     myDF[0].context == 'pieCakeContextMinimalWithPreferences' ? pieCakeContextMinimalWithPreferences :
//     myDF[0].context == 'pieCakeContext' ? pieCakeContext :
//     myDF[0].context == 'pieCakeContextAdditivePreferences' ? pieCakeContextAdditivePreferences :
//     myDF[0].context == 'pieCakeContextBiasedNoPref' ? pieCakeContextBiasedNoPref :
//     myDF[0].context == 'pieCakeContextUnbiasedNoPref' ? pieCakeContextUnbiasedNoPref :
//     false
// Q1(context)

//////////////////////////////////////////////////
// R1 : pragmatic respondent
// ---
// R1's prior beliefs are a distribution over
// different context which differ only wrt
// the questioner's beliefs and/or preferences.
// There are two kinds of R1: a sampler and an
// averager. The former is computationally faster,
// the latter is "normatively correct".
//////////////////////////////////////////////////

// R1 prior beliefs over various contexts

// R1 does not know the belief state of the questioner
var R1PriorContext_beliefsQ1 = {
  confident: pieCakeContextBiasedNoPref,
  unbiased:  pieCakeContextUnbiasedNoPref,
  pessimist: pieCakeContextBiasedPessimist,
  distribution: Categorical({vs: ["confident" , "unbiased",  "pessimist"]})
}

// R1 does not know the preferences of the questoiner
var R1PriorContext_PreferenceQ1 = {
  raspCake:  pieCakeContextAdditivePreferences,
  PieLemon:  pieCakeContextAdditivePreferencesReversed,
  distribution: Categorical({vs: ["raspCake" , "PieLemon"]})
}

// R1 does not know the preferences of the questoiner
var R1PriorContext_BinaryPrefs = {
  raspberry: pieCakeContext_raspberry,
  lemon    : pieCakeContext_lemon,
  distribution: Categorical({vs: ["raspberry" , "lemon"]})
}

var R1ContextPosterior = cache(function(context, question, R1PriorContext) {
  Infer(
    {method:'enumerate'},
    function() {
      var context_label  = sample(R1PriorContext.distribution);
      var context_sample = extend(
        R1PriorContext[context_label],
        {R1PriorOverWorlds: context.R1PriorOverWorlds});
      var questioner = Q1(context_sample);
      // console.log("considering context: ", context_label);
      // console.log("prob of question ", question.text, ": ", questioner.score(question.text));
      factor(questioner.score(question.text));
      return {label: context_label, sample: context_sample, name: context_sample.name}
    }
  )
})

var R1Sampler = cache(function(context, R1PriorContext, question) {
  var getLicensedResponsesR1 = context.getLicensedResponsesR1;
  var responses = filter(function(r) {!isContradiction(context, question, r)},
                         getLicensedResponsesR1(question));
  return Infer({method: 'enumerate'}, function(){
    var context_label  = sample(R1PriorContext.distribution);
    var context_sample = extend(
      R1PriorContext[context_label],
      {R1PriorOverWorlds: context.R1PriorOverWorlds});
    var questioner = Q1(context_sample);
    factor(questioner.score(question.text));
    var response = uniformDraw(responses);
    var ownBeliefs = context.R1PriorOverWorlds;
    var otherBeliefs = updateBeliefs(context_sample.questionerBeliefs, question, response, context_sample);
    var utility = answerUtility(response, ownBeliefs, otherBeliefs, context_sample, params.relevanceBetaR1);
    factor(params.R1Alpha * utility);
    return {context_label, response};
  });
});

var R1Averager = cache(function(context, R1PriorContext, question) {
  var getLicensedResponsesR1 = context.getLicensedResponsesR1;
  var responses = filter(function(r) {!isContradiction(context, question, r)},
                         getLicensedResponsesR1(question));
  var ownBeliefs = context.R1PriorOverWorlds;
  var contextPosterior = marginalize(R1ContextPosterior(context, question, R1PriorContext), 'sample');
  return Infer({method: 'enumerate'}, function(){
    var response = uniformDraw(responses);
    // console.log("considering response: ", response)
    var expectedUtility = expectation(
      contextPosterior,
      function(context_sample) {
        var otherBeliefs = updateBeliefsPragmaticR1(context_sample.questionerBeliefs, question, response, context_sample);
        // console.log("updated beliefs after response: ", response)
        // terminalViz(otherBeliefs, 4)
        return answerUtility(response, ownBeliefs, otherBeliefs, context_sample, params.relevanceBetaR1)
      }
    )
    factor(params.R1Alpha * expectedUtility);
    return response;
  });
});

//  --------------
// | testing area |
//  --------------

var context = pieCakeContextAdditivePreferences;
// var context = pieCakeContextUnbiasedNoPref;
console.log('context: \t', context.name);

var question = context.questions[2];
console.log('question: \t', question.text)

var world = setsOfBakedGoods[10];
// console.log(setsOfBakedGoods);
var context_extended = extend(context, {
  R0PriorOverWorlds: Delta({v: world}),
  R1PriorOverWorlds: Delta({v: world}),
});
console.log('world: \t\t', world);

var responsesR0 = context.getLicensedResponsesR0
// console.log('R0 resp. set: \t', responsesR0(question))

var responseR0 = responsesR0(question)[0]
// console.log('response R0: \t', responseR0)

var meaning = context.meaning
// console.log('truth R0 r.: \t', meaning(world,question,responseR0));

var responsesR1 = context.getLicensedResponsesR1
// console.log('R1 resp. set \t: ', responsesR1(question))

// map(
//   function(world) {
//     console.log("In world ('"+ world +"') the following of R1's responses are true: \n",
//                 filter(function (r) {
//                   meaning(world,question,r)
//                 },
//                        responsesR1(question))
//                )
//   },
//   setsOfBakedGoods
// )

var responseR1 = responsesR1(question)[0]
// console.log('response R1: \t', responseR1)

var meaning = context.meaning
// console.log('truth R1 r.: \t', meaning(world,question,responseR1));

var R0_test = R0(question, context_extended)

console.log("R0:")
terminalViz(R0_test, 4)

var R0Ext_test = R0_extended(question, context_extended)

console.log("R0 (extended):")
terminalViz(R0Ext_test, 4)



//  -------------------------------------
//  testing belief & preference inference
//  -------------------------------------

// belief inference
// var R1posteriorContextBeliefs = R1ContextPosterior(pieCakeContextUnbiasedNoPref, question, R1PriorContext_beliefsQ1);
// console.log("Posterior inference (uncertainty about beliefs)")
// terminalViz(marginalize(R1posteriorContextBeliefs, 'label'),4)

// var R1SamplerBeliefInference  = marginalize(R1Sampler(context_extended, R1PriorContext_beliefsQ1, question), 'response')
// console.log("R1-Sampler (uncertainty about beliefs):")
// terminalViz(R1SamplerBeliefInference,4)

// var R1AveragerBeliefInference = R1Averager(context_extended, R1PriorContext_beliefsQ1, question)
// console.log("R1-Averager (uncertainty about beliefs):")
// terminalViz(R1AveragerBeliefInference,4)

// // preference inference
// var R1posteriorContextPreference = R1ContextPosterior(pieCakeContextUnbiasedNoPref, question, R1PriorContext_PreferenceQ1);
// console.log("Posterior inference (uncertainty about preferences)")
// terminalViz(marginalize(R1posteriorContextPreference, 'label'),4)

// var R1SamplerPreferenceInference  = marginalize(R1Sampler(context_extended, R1PriorContext_PreferenceQ1, question), 'response')
// console.log("R1-Sampler (uncertainty about preferences):")
// terminalViz(R1SamplerPreferenceInference,4)

// var R1AveragerPreferenceInference = R1Averager(context_extended, R1PriorContext_PreferenceQ1, question)
// console.log("R1-Averager (uncertainty about preferences):")
// terminalViz(R1AveragerPreferenceInference,4)

// binary preference inference

var R1posteriorContextPreferenceBinaryQRP = R1ContextPosterior(
  pieCakeContextUnbiasedNoPref,
  context.questions[2],
  R1PriorContext_BinaryPrefs);
console.log("Posterior inference (after RP?)")
terminalViz(marginalize(R1posteriorContextPreferenceBinaryQRP, 'label'),4)

var R1AveragerPreferenceInferenceBinaryQRP = R1Averager(
  context_extended,
  R1PriorContext_BinaryPrefs,
  context.questions[2])
console.log("R1-Averager ('RP?'):")
terminalViz(R1AveragerPreferenceInferenceBinaryQRP,4)


//////////////////////////////////////////////////
// visualization in the browser
// viz(R0(question, context_extended));
// viz(Q1(context));
//////////////////////////////////////////////////

// viz(R1Sampler);
// viz(R1Averager);
